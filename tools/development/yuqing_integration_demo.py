"""
YuQing-newä¸RAG+Agentç³»ç»Ÿé›†æˆæ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨YuQing-newçš„èˆ†æƒ…æ•°æ®è¿›è¡Œæ™ºèƒ½æŠ•èµ„åˆ†æ
"""

import asyncio
import json
import httpx
from datetime import datetime, timedelta
from typing import Dict, List, Any
import os
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../../'))

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["YUQING_API_URL"] = "http://localhost:8000"
os.environ["LLM_GATEWAY_URL"] = "http://localhost:8002/v1/chat/completions"


async def test_yuqing_api_connectivity():
    """æµ‹è¯•YuQing-new APIè¿é€šæ€§"""
    print("ğŸ” æµ‹è¯•YuQing-new APIè¿é€šæ€§...")
    
    yuqing_base_url = "http://localhost:8000"
    
    async with httpx.AsyncClient(timeout=10.0) as client:
        try:
            # 1. å¥åº·æ£€æŸ¥
            health_response = await client.get(f"{yuqing_base_url}/health")
            health_data = health_response.json()
            print(f"âœ… ç³»ç»Ÿå¥åº·çŠ¶æ€: {health_data.get('status')}")
            
            # 2. è·å–ç³»ç»Ÿç»Ÿè®¡
            stats_response = await client.get(f"{yuqing_base_url}/api/news/stats?hours=24")
            stats_data = stats_response.json()
            print(f"ğŸ“Š ç³»ç»Ÿç»Ÿè®¡: {stats_data.get('total_news')}æ¡æ–°é—»ï¼Œ{stats_data.get('recent_24h')}æ¡æœ€è¿‘24å°æ—¶")
            
            # 3. æµ‹è¯•ç»¼åˆæ•°æ®API
            comprehensive_response = await client.get(
                f"{yuqing_base_url}/api/news/comprehensive",
                params={"hours": 6, "limit": 5, "include_entities": True}
            )
            comprehensive_data = comprehensive_response.json()
            print(f"ğŸ” ç»¼åˆæ•°æ®API: è·å–åˆ°{comprehensive_data.get('summary', {}).get('total_analyzed', 0)}æ¡å·²åˆ†ææ–°é—»")
            
            # 4. æµ‹è¯•å®ä½“åˆ†æAPI
            companies_response = await client.get(
                f"{yuqing_base_url}/api/entities/companies",
                params={"limit": 10}
            )
            companies_data = companies_response.json()
            print(f"ğŸ¢ å…¬å¸å®ä½“API: è·å–åˆ°{len(companies_data.get('data', []))}ä¸ªå…¬å¸å®ä½“")
            
            return True
            
        except Exception as e:
            print(f"âŒ YuQing-newè¿æ¥å¤±è´¥: {e}")
            return False


async def demo_yuqing_comprehensive_analysis():
    """æ¼”ç¤ºYuQing-newç»¼åˆåˆ†æåŠŸèƒ½"""
    print("\nğŸ¯ æ¼”ç¤ºYuQing-newç»¼åˆåˆ†æåŠŸèƒ½...")
    
    yuqing_base_url = "http://localhost:8000"
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            # è·å–æœ€è¿‘24å°æ—¶çš„ç»¼åˆæ•°æ®
            response = await client.get(
                f"{yuqing_base_url}/api/news/comprehensive",
                params={
                    "hours": 24,
                    "limit": 10,
                    "include_entities": True,
                    "include_raw_data": False
                }
            )
            response.raise_for_status()
            
            data = response.json()
            
            print(f"ğŸ“ˆ æ•°æ®æ¦‚è§ˆ:")
            summary = data.get("summary", {})
            print(f"  - å·²åˆ†ææ–°é—»: {summary.get('total_analyzed', 0)}æ¡")
            print(f"  - æ—¶é—´èŒƒå›´: {summary.get('time_range_hours', 0)}å°æ—¶")
            print(f"  - å®ä½“ç»Ÿè®¡: {summary.get('entity_counts', {})}")
            
            # åˆ†ææƒ…æ„Ÿåˆ†å¸ƒ
            sentiment_distribution = {"positive": 0, "negative": 0, "neutral": 0}
            impact_levels = {"high": 0, "medium": 0, "low": 0}
            
            print(f"\nğŸ“° æ–°é—»åˆ†æè¯¦æƒ…:")
            for i, item in enumerate(data.get("data", [])[:5], 1):
                news = item.get("news", {})
                sentiment = item.get("sentiment_analysis", {})
                entities = item.get("entity_analysis", {})
                
                print(f"\n  {i}. {news.get('title', 'N/A')[:80]}...")
                print(f"     ğŸ“Š æƒ…æ„Ÿ: {sentiment.get('sentiment_label', 'N/A')} (ç½®ä¿¡åº¦: {sentiment.get('confidence_score', 0):.2f})")
                print(f"     ğŸ¯ å¸‚åœºå½±å“: {sentiment.get('market_impact_level', 'N/A')}")
                print(f"     ğŸ¢ ç›¸å…³å…¬å¸: {len(entities.get('companies', []))}ä¸ª")
                print(f"     ğŸ­ ç›¸å…³è¡Œä¸š: {len(entities.get('industries', []))}ä¸ª")
                
                # ç»Ÿè®¡
                sentiment_label = sentiment.get('sentiment_label', 'neutral')
                sentiment_distribution[sentiment_label] += 1
                
                impact_level = sentiment.get('market_impact_level', 'medium')
                if impact_level in impact_levels:
                    impact_levels[impact_level] += 1
            
            print(f"\nğŸ“Š æƒ…æ„Ÿåˆ†å¸ƒç»Ÿè®¡:")
            total = sum(sentiment_distribution.values())
            if total > 0:
                for sentiment, count in sentiment_distribution.items():
                    percentage = (count / total) * 100
                    print(f"  - {sentiment}: {count}æ¡ ({percentage:.1f}%)")
            
            print(f"\nğŸ¯ å½±å“çº§åˆ«ç»Ÿè®¡:")
            total_impact = sum(impact_levels.values())
            if total_impact > 0:
                for level, count in impact_levels.items():
                    percentage = (count / total_impact) * 100
                    print(f"  - {level}: {count}æ¡ ({percentage:.1f}%)")
            
            return data
            
        except Exception as e:
            print(f"âŒ ç»¼åˆåˆ†ææ¼”ç¤ºå¤±è´¥: {e}")
            return None


async def demo_stock_specific_analysis(stock_codes: List[str] = ["000001", "600036"]):
    """æ¼”ç¤ºç‰¹å®šè‚¡ç¥¨çš„èˆ†æƒ…åˆ†æ"""
    print(f"\nğŸ¯ æ¼”ç¤ºè‚¡ç¥¨ {stock_codes} çš„èˆ†æƒ…åˆ†æ...")
    
    yuqing_base_url = "http://localhost:8000"
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            # 1. è·å–å…¬å¸å®ä½“æ•°æ®
            companies_response = await client.get(
                f"{yuqing_base_url}/api/entities/companies",
                params={"limit": 100}
            )
            companies_data = companies_response.json()
            
            # æŸ¥æ‰¾ç›®æ ‡è‚¡ç¥¨ç›¸å…³çš„å…¬å¸
            target_companies = []
            for company in companies_data.get("data", []):
                stock_code = company.get("stock_code", "")
                if any(code in str(stock_code) for code in stock_codes):
                    target_companies.append(company)
            
            print(f"ğŸ¢ æ‰¾åˆ°ç›¸å…³å…¬å¸: {len(target_companies)}ä¸ª")
            for company in target_companies[:3]:
                print(f"  - {company.get('company_name', 'N/A')} ({company.get('stock_code', 'N/A')})")
                print(f"    å½±å“: {company.get('impact_direction', 'N/A')} | å¼ºåº¦: {company.get('impact_magnitude', 0):.2f}")
            
            # 2. è·å–ç›¸å…³æ–°é—»
            news_response = await client.get(
                f"{yuqing_base_url}/api/news/comprehensive",
                params={"hours": 24, "limit": 50, "include_entities": True}
            )
            news_data = news_response.json()
            
            # è¿‡æ»¤ç›¸å…³æ–°é—»
            relevant_news = []
            for news_item in news_data.get("data", []):
                entity_analysis = news_item.get("entity_analysis", {})
                companies_in_news = entity_analysis.get("companies", [])
                
                for company in companies_in_news:
                    if any(code in str(company.get("stock_code", "")) for code in stock_codes):
                        relevant_news.append(news_item)
                        break
            
            print(f"\nğŸ“° ç›¸å…³æ–°é—»: {len(relevant_news)}æ¡")
            
            # åˆ†æç›¸å…³æ–°é—»çš„æƒ…æ„Ÿè¶‹åŠ¿
            sentiment_scores = []
            for news in relevant_news[:5]:
                sentiment = news.get("sentiment_analysis", {})
                news_title = news.get("news", {}).get("title", "N/A")
                sentiment_label = sentiment.get("sentiment_label", "neutral")
                confidence = sentiment.get("confidence_score", 0)
                
                print(f"  ğŸ“„ {news_title[:60]}...")
                print(f"     æƒ…æ„Ÿ: {sentiment_label} (ç½®ä¿¡åº¦: {confidence:.2f})")
                
                # è½¬æ¢æƒ…æ„Ÿä¸ºæ•°å€¼
                sentiment_score = {"positive": 1, "negative": -1, "neutral": 0}.get(sentiment_label, 0)
                sentiment_scores.append(sentiment_score)
            
            # è®¡ç®—æ•´ä½“æƒ…æ„Ÿ
            if sentiment_scores:
                avg_sentiment = sum(sentiment_scores) / len(sentiment_scores)
                sentiment_trend = "çœ‹æ¶¨" if avg_sentiment > 0.2 else "çœ‹è·Œ" if avg_sentiment < -0.2 else "ä¸­æ€§"
                print(f"\nğŸ“Š æ•´ä½“æƒ…æ„Ÿè¶‹åŠ¿: {sentiment_trend} (å¹³å‡åˆ†: {avg_sentiment:.2f})")
            
            return {
                "target_companies": target_companies,
                "relevant_news": relevant_news,
                "sentiment_analysis": {
                    "average_sentiment": avg_sentiment if sentiment_scores else 0,
                    "sentiment_trend": sentiment_trend if sentiment_scores else "æ— æ•°æ®",
                    "total_relevant_news": len(relevant_news)
                }
            }
            
        except Exception as e:
            print(f"âŒ è‚¡ç¥¨åˆ†ææ¼”ç¤ºå¤±è´¥: {e}")
            return None


async def demo_integrated_rag_agent_analysis():
    """æ¼”ç¤ºå®Œæ•´çš„RAG+AgentæŠ•èµ„åˆ†ææµç¨‹"""
    print(f"\nğŸš€ æ¼”ç¤ºå®Œæ•´çš„RAG+AgentæŠ•èµ„åˆ†ææµç¨‹...")
    
    # æ¨¡æ‹Ÿå¸‚åœºäº‹ä»¶
    market_event = {
        "topic": "æŸç§‘æŠ€å…¬å¸å‘å¸ƒAIæ–°äº§å“",
        "headline": "é©å‘½æ€§AIäº§å“å¼•å‘å¸‚åœºçƒ­è®®ï¼Œç›¸å…³æ¦‚å¿µè‚¡æˆ–å—ç›Š",
        "content": """
        ä»Šæ—¥ï¼ŒæŸçŸ¥åç§‘æŠ€å…¬å¸æ­£å¼å‘å¸ƒäº†å…¶æœ€æ–°ä¸€ä»£äººå·¥æ™ºèƒ½äº§å“ï¼Œè¯¥äº§å“åœ¨å¤šä¸ªæŠ€æœ¯æŒ‡æ ‡ä¸Šå®ç°çªç ´ï¼Œ
        é¢„è®¡å°†æ˜¾è‘—æå‡å…¬å¸åœ¨AIé¢†åŸŸçš„ç«äº‰åŠ›ã€‚å¸‚åœºåˆ†æå¸ˆè®¤ä¸ºï¼Œè¿™ä¸€äº§å“å‘å¸ƒå°†å¯¹æ•´ä¸ªç§‘æŠ€è¡Œä¸šäº§ç”Ÿ
        æ·±è¿œå½±å“ï¼Œç›¸å…³ä¸Šä¸‹æ¸¸å…¬å¸ä¹Ÿå¯èƒ½ä»ä¸­å—ç›Šã€‚æŠ•èµ„è€…å¯¹æ­¤æ¶ˆæ¯ååº”ç§¯æï¼Œç›¸å…³æ¦‚å¿µè‚¡åœ¨ç›˜å‰äº¤æ˜“
        ä¸­å‡ºç°ä¸Šæ¶¨ã€‚åˆ†æå¸ˆå»ºè®®å…³æ³¨äº§å“å•†ä¸šåŒ–è¿›å±•å’Œå¸‚åœºæ¥å—åº¦ã€‚
        """,
        "symbols": ["000001", "600036", "002415"],
        "time_horizon": "medium",
        "risk_appetite": "balanced",
        "region": "CN",
        "max_iterations": 2
    }
    
    # è°ƒç”¨å¢å¼ºç‰ˆå¤šæ™ºèƒ½ä½“åˆ†æç³»ç»Ÿ
    analysis_orchestrator_url = "http://localhost:8010"
    
    async with httpx.AsyncClient(timeout=120.0) as client:
        try:
            print("ğŸ­ å¯åŠ¨å¤šæ™ºèƒ½ä½“æŠ•ç ”åˆ†æ...")
            
            response = await client.post(
                f"{analysis_orchestrator_url}/v1/analysis/execute",
                json=market_event
            )
            response.raise_for_status()
            
            analysis_result = response.json()
            
            print("âœ… åˆ†æå®Œæˆï¼")
            print(f"\nğŸ“‹ æŠ•èµ„å§”å‘˜ä¼šçºªè¦:")
            
            committee_minutes = analysis_result.get("committee_minutes", {})
            if committee_minutes:
                print(f"  ä¼šè®®ID: {committee_minutes.get('meeting_id')}")
                print(f"  å‚ä¸è€…: {', '.join(committee_minutes.get('participants', []))}")
                print(f"  è®¨è®ºè½®æ¬¡: {committee_minutes.get('discussion_rounds')}è½®")
                print(f"  æœ€ç»ˆå†³è®®: {committee_minutes.get('final_resolution')}")
                
                key_debates = committee_minutes.get('key_debates', [])
                if key_debates:
                    print(f"\nğŸ”¥ å…³é”®äº‰è®®ç‚¹:")
                    for debate in key_debates:
                        print(f"  - {debate.get('topic')}: {debate.get('positions')}")
            
            # æ˜¾ç¤ºå¢å¼ºç‰ˆå†³ç­–
            enhanced_decision = analysis_result.get("enhanced_decision", {})
            if enhanced_decision:
                base_decision = enhanced_decision.get("base_decision", {})
                print(f"\nğŸ’¡ æŠ•èµ„å†³ç­–:")
                print(f"  è¡ŒåŠ¨å»ºè®®: {base_decision.get('action')}")
                print(f"  åŸºç¡€ä¿¡å¿ƒåº¦: {base_decision.get('confidence', 0):.2f}")
                print(f"  é£é™©è°ƒæ•´åä¿¡å¿ƒåº¦: {enhanced_decision.get('risk_adjusted_confidence', 0):.2f}")
                print(f"  å®è§‚åŒ¹é…åº¦: {enhanced_decision.get('macro_alignment', 0):.2f}")
                print(f"  æ•°æ®è´¨é‡å› å­: {enhanced_decision.get('data_quality_factor', 0):.2f}")
            
            # æ˜¾ç¤ºæ•°æ®æƒ…æŠ¥ä¸“å®¶çš„åˆ†æ
            enhanced_findings = analysis_result.get("enhanced_findings", {})
            if enhanced_findings:
                data_intelligence = enhanced_findings.get("data_intelligence", {})
                if data_intelligence:
                    market_snapshot = data_intelligence.get("market_snapshot", {})
                    sentiment_indicators = data_intelligence.get("sentiment_indicators", {})
                    
                    print(f"\nğŸ“Š æ•°æ®æƒ…æŠ¥æ‘˜è¦:")
                    print(f"  æ•´ä½“æƒ…æ„Ÿ: {market_snapshot.get('overall_sentiment', {})}")
                    print(f"  æ•°æ®ä¸€è‡´æ€§è¯„åˆ†: {market_snapshot.get('consistency_score', 0):.2f}")
                    print(f"  å¼‚å¸¸æƒ…å†µ: {market_snapshot.get('anomaly_count', 0)}ä¸ª")
                    
                    hot_topics = sentiment_indicators.get("hot_topics", [])
                    if hot_topics:
                        print(f"  çƒ­é—¨è¯é¢˜: {', '.join([topic.get('keyword', '') for topic in hot_topics[:5]])}")
            
            return analysis_result
            
        except httpx.ConnectError:
            print("âŒ æ— æ³•è¿æ¥åˆ°åˆ†æç¼–æ’å™¨ï¼Œè¯·ç¡®ä¿æœåŠ¡å·²å¯åŠ¨ (http://localhost:8010)")
            return None
        except Exception as e:
            print(f"âŒ åˆ†ææµç¨‹å¤±è´¥: {e}")
            return None


async def demo_yuqing_entity_extraction():
    """æ¼”ç¤ºYuQing-newçš„å®ä½“æå–åŠŸèƒ½"""
    print(f"\nğŸ” æ¼”ç¤ºYuQing-newå®ä½“æå–åŠŸèƒ½...")
    
    test_text = """
    è…¾è®¯æ§è‚¡ä»Šæ—¥å‘å¸ƒ2024å¹´ç¬¬ä¸‰å­£åº¦è´¢æŠ¥ï¼Œè¥æ”¶åŒæ¯”å¢é•¿8%è‡³1546äº¿å…ƒï¼Œå‡€åˆ©æ¶¦å¢é•¿47%è‡³537äº¿å…ƒã€‚
    CEOé©¬åŒ–è…¾è¡¨ç¤ºï¼Œå…¬å¸åœ¨äººå·¥æ™ºèƒ½å’Œäº‘è®¡ç®—é¢†åŸŸçš„æŠ•èµ„å¼€å§‹æ˜¾ç°å›æŠ¥ã€‚åˆ†æå¸ˆè®¤ä¸ºï¼Œè…¾è®¯çš„æ¸¸æˆä¸šåŠ¡
    å’Œå¹¿å‘Šä¸šåŠ¡è¡¨ç°å¼ºåŠ²ï¼Œé¢„è®¡æœªæ¥å‡ ä¸ªå­£åº¦å°†ç»§ç»­ä¿æŒå¢é•¿åŠ¿å¤´ã€‚æŠ•èµ„é“¶è¡Œæ‘©æ ¹å¤§é€šå°†è…¾è®¯ç›®æ ‡ä»·
    ä¸Šè°ƒè‡³450æ¸¯å…ƒï¼Œç»´æŒ"å¢æŒ"è¯„çº§ã€‚
    """
    
    yuqing_base_url = "http://localhost:8000"
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            response = await client.post(
                f"{yuqing_base_url}/api/entities/entities/extract",
                json={
                    "text": test_text,
                    "enable_sentiment": True
                }
            )
            response.raise_for_status()
            
            extraction_result = response.json()
            
            print("âœ… å®ä½“æå–å®Œæˆï¼")
            
            entities = extraction_result.get("entities", {})
            
            companies = entities.get("companies", [])
            if companies:
                print(f"\nğŸ¢ è¯†åˆ«åˆ°çš„å…¬å¸ ({len(companies)}ä¸ª):")
                for company in companies:
                    print(f"  - {company.get('name', 'N/A')}")
                    print(f"    è‚¡ç¥¨ä»£ç : {company.get('stock_code', 'N/A')}")
                    print(f"    å½±å“æ–¹å‘: {company.get('impact_direction', 'N/A')}")
                    print(f"    å½±å“å¼ºåº¦: {company.get('impact_magnitude', 0):.2f}")
            
            persons = entities.get("persons", [])
            if persons:
                print(f"\nğŸ‘¤ è¯†åˆ«åˆ°çš„äººç‰© ({len(persons)}ä¸ª):")
                for person in persons:
                    print(f"  - {person.get('name', 'N/A')} ({person.get('position_title', 'N/A')})")
                    print(f"    æ‰€å±å…¬å¸: {person.get('company_affiliation', 'N/A')}")
                    print(f"    å½±å“åŠ›: {person.get('influence_level', 'N/A')}")
            
            industries = entities.get("industries", [])
            if industries:
                print(f"\nğŸ­ è¯†åˆ«åˆ°çš„è¡Œä¸š ({len(industries)}ä¸ª):")
                for industry in industries:
                    print(f"  - {industry.get('name', 'N/A')}")
                    print(f"    å½±å“æ–¹å‘: {industry.get('impact_direction', 'N/A')}")
                    print(f"    å½±å“å¼ºåº¦: {industry.get('impact_magnitude', 0):.2f}")
            
            events = entities.get("events", [])
            if events:
                print(f"\nğŸ“… è¯†åˆ«åˆ°çš„äº‹ä»¶ ({len(events)}ä¸ª):")
                for event in events:
                    print(f"  - {event.get('type', 'N/A')}: {event.get('description', 'N/A')}")
                    print(f"    å¸‚åœºé‡è¦æ€§: {event.get('market_significance', 'N/A')}")
            
            return extraction_result
            
        except Exception as e:
            print(f"âŒ å®ä½“æå–æ¼”ç¤ºå¤±è´¥: {e}")
            return None


async def demo_market_hotspots_discovery():
    """æ¼”ç¤ºå¸‚åœºçƒ­ç‚¹å‘ç°åŠŸèƒ½"""
    print(f"\nğŸ”¥ æ¼”ç¤ºå¸‚åœºçƒ­ç‚¹å‘ç°åŠŸèƒ½...")
    
    yuqing_base_url = "http://localhost:8000"
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            # å¹¶è¡Œè·å–çƒ­ç‚¹æ•°æ®
            tasks = [
                client.get(f"{yuqing_base_url}/api/analysis/hotspots/discover", 
                          params={"hours": 6, "limit": 10}),
                client.get(f"{yuqing_base_url}/api/analysis/keywords/trending",
                          params={"hours": 24, "limit": 15}),
                client.get(f"{yuqing_base_url}/api/analysis/stats/sentiment",
                          params={"hours": 24})
            ]
            
            responses = await asyncio.gather(*tasks, return_exceptions=True)
            
            # è§£æçƒ­ç‚¹å‘ç°ç»“æœ
            if not isinstance(responses[0], Exception):
                hotspots_data = responses[0].json()
                hotspots = hotspots_data.get("data", [])
                
                print(f"ğŸ”¥ å‘ç°çƒ­ç‚¹: {len(hotspots)}ä¸ª")
                for i, hotspot in enumerate(hotspots[:5], 1):
                    print(f"  {i}. {hotspot.get('title', 'N/A')}")
                    print(f"     çƒ­åº¦åˆ†æ•°: {hotspot.get('hotness_score', 0):.2f}")
                    print(f"     ç›¸å…³åº¦: {hotspot.get('relevance_score', 0):.2f}")
            
            # è§£æè¶‹åŠ¿å…³é”®è¯
            if not isinstance(responses[1], Exception):
                keywords_data = responses[1].json()
                keywords = keywords_data.get("data", [])
                
                print(f"\nğŸ¯ è¶‹åŠ¿å…³é”®è¯: {len(keywords)}ä¸ª")
                trending_words = [kw.get('keyword', '') for kw in keywords[:10]]
                print(f"  {', '.join(trending_words)}")
            
            # è§£ææƒ…æ„Ÿç»Ÿè®¡
            if not isinstance(responses[2], Exception):
                sentiment_data = responses[2].json()
                sentiment_stats = sentiment_data.get("data", {})
                
                print(f"\nğŸ“Š 24å°æ—¶æƒ…æ„Ÿç»Ÿè®¡:")
                print(f"  æ­£é¢æƒ…æ„Ÿæ¯”ä¾‹: {sentiment_stats.get('positive_ratio', 0):.2%}")
                print(f"  è´Ÿé¢æƒ…æ„Ÿæ¯”ä¾‹: {sentiment_stats.get('negative_ratio', 0):.2%}")
                print(f"  ä¸­æ€§æƒ…æ„Ÿæ¯”ä¾‹: {sentiment_stats.get('neutral_ratio', 0):.2%}")
            
            return {
                "hotspots": hotspots if not isinstance(responses[0], Exception) else [],
                "trending_keywords": keywords if not isinstance(responses[1], Exception) else [],
                "sentiment_stats": sentiment_stats if not isinstance(responses[2], Exception) else {}
            }
            
        except Exception as e:
            print(f"âŒ çƒ­ç‚¹å‘ç°æ¼”ç¤ºå¤±è´¥: {e}")
            return None


async def create_integration_test_report():
    """ç”Ÿæˆé›†æˆæµ‹è¯•æŠ¥å‘Š"""
    print("ğŸ“ ç”ŸæˆYuQing-newé›†æˆæµ‹è¯•æŠ¥å‘Š...")
    
    report = {
        "test_timestamp": datetime.now().isoformat(),
        "yuqing_connectivity": False,
        "comprehensive_analysis": None,
        "stock_analysis": None,
        "entity_extraction": None,
        "hotspot_discovery": None,
        "integration_status": "æœªçŸ¥"
    }
    
    try:
        # 1. è¿é€šæ€§æµ‹è¯•
        report["yuqing_connectivity"] = await test_yuqing_api_connectivity()
        
        if report["yuqing_connectivity"]:
            # 2. ç»¼åˆåˆ†ææµ‹è¯•
            report["comprehensive_analysis"] = await demo_yuqing_comprehensive_analysis()
            
            # 3. è‚¡ç¥¨åˆ†ææµ‹è¯•
            report["stock_analysis"] = await demo_stock_specific_analysis(["000001", "600036"])
            
            # 4. å®ä½“æå–æµ‹è¯•
            report["entity_extraction"] = await demo_yuqing_entity_extraction()
            
            # 5. çƒ­ç‚¹å‘ç°æµ‹è¯•
            report["hotspot_discovery"] = await demo_market_hotspots_discovery()
            
            # 6. å®Œæ•´RAG+Agentåˆ†ææµ‹è¯•
            print("\n" + "="*60)
            print("ğŸ¯ å¼€å§‹å®Œæ•´çš„RAG+Agentåˆ†ææµ‹è¯•...")
            print("="*60)
            
            rag_result = await demo_integrated_rag_agent_analysis()
            report["rag_agent_analysis"] = rag_result is not None
            
            # è¯„ä¼°é›†æˆçŠ¶æ€
            success_count = sum([
                report["yuqing_connectivity"],
                report["comprehensive_analysis"] is not None,
                report["stock_analysis"] is not None,
                report["entity_extraction"] is not None,
                report["hotspot_discovery"] is not None,
                report["rag_agent_analysis"]
            ])
            
            if success_count >= 5:
                report["integration_status"] = "ä¼˜ç§€"
            elif success_count >= 3:
                report["integration_status"] = "è‰¯å¥½"
            elif success_count >= 1:
                report["integration_status"] = "éƒ¨åˆ†å¯ç”¨"
            else:
                report["integration_status"] = "å¤±è´¥"
        
        else:
            report["integration_status"] = "YuQing-newæœåŠ¡ä¸å¯ç”¨"
    
    except Exception as e:
        report["integration_status"] = f"æµ‹è¯•å¼‚å¸¸: {str(e)}"
    
    # è¾“å‡ºæŠ¥å‘Šæ‘˜è¦
    print(f"\n" + "="*60)
    print(f"ğŸ“Š YuQing-newé›†æˆæµ‹è¯•æŠ¥å‘Š")
    print("="*60)
    print(f"ğŸ”— è¿é€šæ€§: {'âœ…' if report['yuqing_connectivity'] else 'âŒ'}")
    print(f"ğŸ“ˆ ç»¼åˆåˆ†æ: {'âœ…' if report['comprehensive_analysis'] else 'âŒ'}")
    print(f"ğŸ¯ è‚¡ç¥¨åˆ†æ: {'âœ…' if report['stock_analysis'] else 'âŒ'}")
    print(f"ğŸ¢ å®ä½“æå–: {'âœ…' if report['entity_extraction'] else 'âŒ'}")
    print(f"ğŸ”¥ çƒ­ç‚¹å‘ç°: {'âœ…' if report['hotspot_discovery'] else 'âŒ'}")
    print(f"ğŸ¤– RAG+Agent: {'âœ…' if report.get('rag_agent_analysis') else 'âŒ'}")
    print(f"ğŸ† é›†æˆçŠ¶æ€: {report['integration_status']}")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_path = "yuqing_integration_test_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    return report


async def main():
    """ä¸»å‡½æ•° - è¿è¡Œå®Œæ•´çš„é›†æˆæ¼”ç¤º"""
    print("ğŸ‰ æ¬¢è¿ä½¿ç”¨YuQing-newä¸RAG+Agentç³»ç»Ÿé›†æˆæ¼”ç¤ºï¼")
    print("="*60)
    
    # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒé…ç½®
    yuqing_url = os.getenv("YUQING_API_URL", "http://localhost:8000")
    llm_url = os.getenv("LLM_GATEWAY_URL", "http://localhost:8002/v1/chat/completions")
    
    print(f"ğŸ”§ ç¯å¢ƒé…ç½®:")
    print(f"  YuQing-new API: {yuqing_url}")
    print(f"  LLM Gateway: {llm_url}")
    print()
    
    # è¿è¡Œé›†æˆæµ‹è¯•
    report = await create_integration_test_report()
    
    print(f"\nğŸŠ é›†æˆæ¼”ç¤ºå®Œæˆï¼")
    
    if report["integration_status"] in ["ä¼˜ç§€", "è‰¯å¥½"]:
        print("ğŸš€ ç³»ç»Ÿé›†æˆæˆåŠŸï¼æ‚¨å¯ä»¥å¼€å§‹ä½¿ç”¨YuQing-newé©±åŠ¨çš„æŠ•ç ”åˆ†æç³»ç»Ÿäº†ï¼")
        
        print(f"\nğŸ”§ ä½¿ç”¨å»ºè®®:")
        print(f"  1. ç¡®ä¿YuQing-newæœåŠ¡è¿è¡Œåœ¨ {yuqing_url}")
        print(f"  2. ç¡®ä¿RAG+AgentæœåŠ¡è¿è¡Œåœ¨ http://localhost:8010")
        print(f"  3. é…ç½®ç¯å¢ƒå˜é‡ YUQING_API_URL æŒ‡å‘YuQing-newæœåŠ¡")
        print(f"  4. è°ƒç”¨ /v1/analysis/execute æ¥å£å¼€å§‹åˆ†æ")
    
    else:
        print("âš ï¸  ç³»ç»Ÿé›†æˆå­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€å’Œé…ç½®ã€‚")
        
        print(f"\nğŸ”§ æ•…éšœæ’é™¤:")
        print(f"  1. æ£€æŸ¥YuQing-newæ˜¯å¦æ­£å¸¸è¿è¡Œ: {yuqing_url}/health")
        print(f"  2. æ£€æŸ¥RAG+AgentæœåŠ¡æ˜¯å¦å¯åŠ¨: http://localhost:8010/health")
        print(f"  3. éªŒè¯ç½‘ç»œè¿æ¥å’Œç«¯å£é…ç½®")
        print(f"  4. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æ’æŸ¥å…·ä½“é”™è¯¯")


if __name__ == "__main__":
    asyncio.run(main())
