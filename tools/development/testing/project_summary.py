#!/usr/bin/env python3
"""
é¡¹ç›®ç»Ÿè®¡è„šæœ¬
ç”Ÿæˆé¡¹ç›®çš„ä»£ç ç»Ÿè®¡ã€æŠ€æœ¯æ ˆåˆ†æç­‰ä¿¡æ¯
"""

import os
import subprocess
from pathlib import Path
from collections import defaultdict
import json

def count_lines_of_code():
    """ç»Ÿè®¡ä»£ç è¡Œæ•°"""
    extensions = {'.py', '.md', '.yml', '.yaml', '.toml', '.txt', '.sh', '.json'}
    stats = defaultdict(int)
    total_lines = 0
    
    for root, dirs, files in os.walk('.'):
        # è·³è¿‡ä¸éœ€è¦çš„ç›®å½•
        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules', 'venv']]
        
        for file in files:
            if any(file.endswith(ext) for ext in extensions):
                file_path = os.path.join(root, file)
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        lines = len(f.readlines())
                        ext = Path(file).suffix or 'no_ext'
                        stats[ext] += lines
                        total_lines += lines
                except:
                    continue
    
    return stats, total_lines

def analyze_project_structure():
    """åˆ†æé¡¹ç›®ç»“æ„"""
    structure = {
        'services': [],
        'scripts': [],
        'docs': [],
        'config_files': []
    }
    
    # ç»Ÿè®¡å¾®æœåŠ¡
    services_dir = Path('services')
    if services_dir.exists():
        for service_dir in services_dir.iterdir():
            if service_dir.is_dir():
                py_files = len(list(service_dir.glob('*.py')))
                structure['services'].append({
                    'name': service_dir.name,
                    'python_files': py_files
                })
    
    # ç»Ÿè®¡è„šæœ¬
    scripts_dir = Path('scripts')
    if scripts_dir.exists():
        for script in scripts_dir.iterdir():
            if script.is_file():
                structure['scripts'].append(script.name)
    
    # ç»Ÿè®¡æ–‡æ¡£
    for file in Path('.').glob('*.md'):
        structure['docs'].append(file.name)
    
    # ç»Ÿè®¡é…ç½®æ–‡ä»¶
    config_patterns = ['*.yml', '*.yaml', '*.toml', '*.ini', 'Procfile', 'docker-compose*']
    for pattern in config_patterns:
        for file in Path('.').glob(pattern):
            structure['config_files'].append(file.name)
    
    return structure

def get_git_stats():
    """è·å–Gitç»Ÿè®¡ä¿¡æ¯"""
    try:
        # è·å–æäº¤æ•°é‡
        commit_count = subprocess.check_output(['git', 'rev-list', '--count', 'HEAD'], 
                                             stderr=subprocess.DEVNULL).decode().strip()
        
        # è·å–æ–‡ä»¶æ•°é‡
        tracked_files = subprocess.check_output(['git', 'ls-files'], 
                                              stderr=subprocess.DEVNULL).decode().strip().split('\n')
        
        return {
            'commits': int(commit_count) if commit_count.isdigit() else 0,
            'tracked_files': len([f for f in tracked_files if f])
        }
    except:
        return {'commits': 'N/A', 'tracked_files': 'N/A'}

def generate_tech_stack_summary():
    """ç”ŸæˆæŠ€æœ¯æ ˆæ‘˜è¦"""
    tech_stack = {
        'backend_frameworks': ['FastAPI 0.104.1', 'LangChain 0.0.335'],
        'ai_models': ['DeepSeek v3', 'BGE-Large-ZH-v1.5', 'Sentence-Transformers'],
        'databases': ['PostgreSQL 15', 'ChromaDB 0.4.18', 'Redis 7'],
        'development_tools': ['Docker Compose', 'Honcho', 'Alembic', 'Black + Ruff'],
        'languages': ['Python 3.10+'],
        'deployment': ['AWS Lambda', 'AWS EC2', 'AWS RDS', 'Pinecone (ç”Ÿäº§)']
    }
    return tech_stack

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“Š æ™ºç­– (InsightFolio) é¡¹ç›®ç»Ÿè®¡æŠ¥å‘Š")
    print("=" * 60)
    
    # ä»£ç ç»Ÿè®¡
    print("\nğŸ“ ä»£ç ç»Ÿè®¡:")
    code_stats, total_lines = count_lines_of_code()
    print(f"æ€»ä»£ç è¡Œæ•°: {total_lines:,}")
    for ext, lines in sorted(code_stats.items(), key=lambda x: x[1], reverse=True):
        print(f"  {ext}: {lines:,} è¡Œ")
    
    # é¡¹ç›®ç»“æ„
    print("\nğŸ—ï¸ é¡¹ç›®ç»“æ„:")
    structure = analyze_project_structure()
    
    print(f"å¾®æœåŠ¡æ•°é‡: {len(structure['services'])}")
    for service in structure['services']:
        print(f"  - {service['name']}: {service['python_files']} ä¸ªPythonæ–‡ä»¶")
    
    print(f"\nè„šæœ¬æ•°é‡: {len(structure['scripts'])}")
    for script in structure['scripts'][:5]:  # æ˜¾ç¤ºå‰5ä¸ª
        print(f"  - {script}")
    
    print(f"\næ–‡æ¡£æ•°é‡: {len(structure['docs'])}")
    for doc in structure['docs']:
        print(f"  - {doc}")
    
    print(f"\né…ç½®æ–‡ä»¶: {len(structure['config_files'])}")
    for config in structure['config_files']:
        print(f"  - {config}")
    
    # Gitç»Ÿè®¡
    print("\nğŸ“ˆ ç‰ˆæœ¬æ§åˆ¶:")
    git_stats = get_git_stats()
    print(f"Gitæäº¤æ•°: {git_stats['commits']}")
    print(f"è·Ÿè¸ªæ–‡ä»¶æ•°: {git_stats['tracked_files']}")
    
    # æŠ€æœ¯æ ˆ
    print("\nğŸ› ï¸ æŠ€æœ¯æ ˆ:")
    tech_stack = generate_tech_stack_summary()
    for category, technologies in tech_stack.items():
        print(f"{category.replace('_', ' ').title()}:")
        for tech in technologies:
            print(f"  - {tech}")
        print()
    
    # åŠŸèƒ½ç‰¹æ€§
    print("ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ç‰¹æ€§:")
    features = [
        "âœ… å¾®æœåŠ¡æ¶æ„ (4ä¸ªæ ¸å¿ƒæœåŠ¡)",
        "âœ… RAGæ£€ç´¢å¢å¼ºç”Ÿæˆ",  
        "âœ… è‚¡ç¥¨åˆ†æAgent",
        "âœ… å®æ—¶è‚¡ç¥¨æ•°æ®é›†æˆ",
        "âœ… DeepSeek v3å¤§æ¨¡å‹",
        "âœ… ä¸­æ–‡è¯­ä¹‰ç†è§£",
        "âœ… å‘é‡æ•°æ®åº“æ£€ç´¢",
        "âœ… æ™ºèƒ½ç¼“å­˜ä¼˜åŒ–",
        "âœ… å¼‚æ­¥é«˜æ€§èƒ½æ¶æ„",
        "âœ… å®Œæ•´APIæ–‡æ¡£",
        "âœ… å¼€ç®±å³ç”¨æ¼”ç¤º"
    ]
    
    for feature in features:
        print(f"  {feature}")
    
    # é¡¹ç›®è§„æ¨¡è¯„ä¼°
    print(f"\nğŸ“ é¡¹ç›®è§„æ¨¡è¯„ä¼°:")
    complexity_score = 0
    complexity_score += len(structure['services']) * 10  # å¾®æœåŠ¡æ•°é‡
    complexity_score += total_lines // 100  # ä»£ç è¡Œæ•°
    complexity_score += len(structure['docs']) * 2  # æ–‡æ¡£æ•°é‡
    
    if complexity_score < 50:
        scale = "å°å‹é¡¹ç›®"
    elif complexity_score < 150:
        scale = "ä¸­å‹é¡¹ç›®"
    else:
        scale = "å¤§å‹é¡¹ç›®"
    
    print(f"é¡¹ç›®è§„æ¨¡: {scale} (å¤æ‚åº¦åˆ†æ•°: {complexity_score})")
    print(f"å¼€å‘å‘¨æœŸä¼°ç®—: çº¦ {max(1, complexity_score // 20)} äººæœˆ")
    print(f"å›¢é˜Ÿè§„æ¨¡å»ºè®®: {max(1, len(structure['services']))} - {len(structure['services']) * 2} äºº")
    
    # ç”ŸæˆJSONæŠ¥å‘Š
    report = {
        'timestamp': str(subprocess.check_output(['date'], stderr=subprocess.DEVNULL).decode().strip()),
        'code_stats': dict(code_stats),
        'total_lines': total_lines,
        'structure': structure,
        'git_stats': git_stats,
        'tech_stack': tech_stack,
        'complexity_score': complexity_score,
        'project_scale': scale
    }
    
    with open('project_summary.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: project_summary.json")
    print("\n" + "=" * 60)
    print("âœ¨ é¡¹ç›®ç»Ÿè®¡å®Œæˆï¼")

if __name__ == "__main__":
    main()
