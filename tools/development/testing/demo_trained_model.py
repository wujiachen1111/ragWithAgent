#!/usr/bin/env python3
"""
è®­ç»ƒåæ¨¡å‹æ•ˆæœæ¼”ç¤ºè„šæœ¬
å±•ç¤ºAè‚¡ç‰¹åŒ–å¯¹æ¯”å­¦ä¹ RAGæ¨¡å‹çš„å®é™…æ•ˆæœ
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root / "services" / "decision_engine"))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TrainedModelDemo:
    """è®­ç»ƒæ¨¡å‹æ¼”ç¤ºå™¨"""
    
    def __init__(self, model_path: str = None):
        self.project_root = project_root
        self.model = None
        self.baseline_model = None
        
        # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        if model_path and Path(model_path).exists():
            self.model_path = Path(model_path)
        else:
            # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹
            checkpoint_dir = self.project_root / "checkpoints"
            if checkpoint_dir.exists():
                best_model = checkpoint_dir / "best_model.pth"
                if best_model.exists():
                    self.model_path = best_model
                else:
                    self.model_path = None
            else:
                self.model_path = None
        
        # æµ‹è¯•æ ·æœ¬å¯¹
        self.test_samples = [
            {
                "anchor": "å…¬å¸å‘å¸ƒå‘˜å·¥æŒè‚¡è®¡åˆ’ï¼Œæ¿€åŠ±æ ¸å¿ƒéª¨å¹²å›¢é˜Ÿ",
                "positive": "å…¬å¸å…¬å¸ƒè‚¡æƒæ¿€åŠ±è®¡åˆ’ï¼Œç»‘å®šæ ¸å¿ƒå›¢é˜Ÿåˆ©ç›Š",
                "hard_negative": "å…¬å¸æ§è‚¡è‚¡ä¸œå‘å¸ƒå‡æŒè®¡åˆ’ï¼Œæ‹Ÿå¤§å¹…å¥—ç°ç¦»åœº",
                "category": "è‚¡æƒå˜åŠ¨",
                "explanation": "å‘˜å·¥æŒè‚¡ä¸ºåˆ©å¥½ï¼Œè‚¡ä¸œå‡æŒä¸ºåˆ©ç©º"
            },
            {
                "anchor": "äº§å“æˆåŠŸè·å¾—æµ·å¤–å¤§é¢è®¢å•ï¼Œä¸šåŠ¡æ‹“å±•é¡ºåˆ©",
                "positive": "å…¬å¸äº§å“å‡ºå£è®¢å•æ¿€å¢ï¼Œå›½é™…åŒ–è¿›ç¨‹åŠ é€Ÿ",  
                "hard_negative": "äº§å“é­é‡æµ·å¤–åå€¾é”€è°ƒæŸ¥ï¼Œå‡ºå£å—é˜»",
                "category": "ä¸šåŠ¡å‘å±•", 
                "explanation": "è·å¾—è®¢å•ä¸ºåˆ©å¥½ï¼Œåå€¾é”€è°ƒæŸ¥ä¸ºåˆ©ç©º"
            },
            {
                "anchor": "å…¬å¸å‘å¸ƒä¸šç»©é¢„å¢å…¬å‘Šï¼Œå‡€åˆ©æ¶¦å¤§å¹…æå‡",
                "positive": "ä¸šç»©è¶…é¢„æœŸå¢é•¿ï¼Œç›ˆåˆ©èƒ½åŠ›æ˜¾è‘—æ”¹å–„",
                "hard_negative": "å…¬å¸å‘å¸ƒä¸šç»©é¢„è­¦ï¼Œå‡€åˆ©æ¶¦å¯èƒ½å¤§å¹…ä¸‹æ»‘",
                "category": "è´¢åŠ¡çŠ¶å†µ",
                "explanation": "ä¸šç»©é¢„å¢ä¸ºåˆ©å¥½ï¼Œä¸šç»©é¢„è­¦ä¸ºåˆ©ç©º"
            },
            {
                "anchor": "è‚¡ä»·çªç ´é‡è¦é˜»åŠ›ä½ï¼ŒæŠ€æœ¯é¢è½¬å¼º",
                "positive": "è‚¡ä»·æ”¾é‡çªç ´ï¼ŒæŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºä¹°å…¥ä¿¡å·",
                "hard_negative": "è‚¡ä»·è·Œç ´é‡è¦æ”¯æ’‘ä½ï¼ŒæŠ€æœ¯é¢è½¬å¼±", 
                "category": "æŠ€æœ¯åˆ†æ",
                "explanation": "æŠ€æœ¯çªç ´ä¸ºåˆ©å¥½ï¼ŒæŠ€æœ¯ç ´ä½ä¸ºåˆ©ç©º"
            },
            {
                "anchor": "æ”¿ç­–åˆ©å¥½é¢‘å‡ºï¼Œè¡Œä¸šæ™¯æ°”åº¦æŒç»­æå‡",
                "positive": "å›½å®¶æ”¿ç­–å¤§åŠ›æ”¯æŒï¼Œè¡Œä¸šè¿æ¥å‘å±•æœºé‡",
                "hard_negative": "ç›‘ç®¡æ”¿ç­–è¶‹ä¸¥ï¼Œè¡Œä¸šé¢ä¸´åˆè§„å‹åŠ›",
                "category": "æ”¿ç­–ç¯å¢ƒ", 
                "explanation": "æ”¿ç­–åˆ©å¥½ä¸ºåˆ©å¥½ï¼Œç›‘ç®¡è¶‹ä¸¥ä¸ºåˆ©ç©º"
            }
        ]
    
    def load_models(self) -> bool:
        """åŠ è½½è®­ç»ƒæ¨¡å‹å’ŒåŸºçº¿æ¨¡å‹"""
        try:
            from contrastive_rag_enhancer import ContrastiveEmbeddingModel
            from sentence_transformers import SentenceTransformer
            
            # åŠ è½½è®­ç»ƒåçš„æ¨¡å‹
            if self.model_path and self.model_path.exists():
                logger.info(f"ğŸ“¥ åŠ è½½è®­ç»ƒæ¨¡å‹: {self.model_path}")
                
                self.model = ContrastiveEmbeddingModel()
                checkpoint = torch.load(self.model_path, map_location='cpu')  # TODO: Consider using weights_only=True for security
                self.model.load_state_dict(checkpoint['model_state_dict'])
                self.model.eval()
                
                logger.info("âœ… è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                logger.warning("âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒæ¨¡å‹ï¼Œå°†åªä½¿ç”¨åŸºçº¿æ¨¡å‹")
                return False
            
            # åŠ è½½åŸºçº¿æ¨¡å‹ç”¨äºå¯¹æ¯”
            logger.info("ğŸ“¥ åŠ è½½åŸºçº¿æ¨¡å‹: BAAI/bge-large-zh-v1.5")
            self.baseline_model = SentenceTransformer("BAAI/bge-large-zh-v1.5")
            logger.info("âœ… åŸºçº¿æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def test_single_sample(self, sample: Dict, model, model_name: str) -> Dict:
        """æµ‹è¯•å•ä¸ªæ ·æœ¬"""
        try:
            if model_name == "è®­ç»ƒæ¨¡å‹" and self.model:
                # ä½¿ç”¨è®­ç»ƒæ¨¡å‹
                with torch.no_grad():
                    anchor_emb = model.encode([sample['anchor']])
                    positive_emb = model.encode([sample['positive']])  
                    negative_emb = model.encode([sample['hard_negative']])
                
                pos_sim = torch.cosine_similarity(anchor_emb, positive_emb, dim=1).item()
                neg_sim = torch.cosine_similarity(anchor_emb, negative_emb, dim=1).item()
                
            else:
                # ä½¿ç”¨åŸºçº¿æ¨¡å‹
                anchor_emb = model.encode([sample['anchor']])
                positive_emb = model.encode([sample['positive']])
                negative_emb = model.encode([sample['hard_negative']])
                
                from sklearn.metrics.pairwise import cosine_similarity
                pos_sim = cosine_similarity(anchor_emb, positive_emb)[0][0]
                neg_sim = cosine_similarity(anchor_emb, negative_emb)[0][0]
            
            # åˆ¤æ–­æ˜¯å¦æ­£ç¡®ï¼ˆæ­£æ ·æœ¬ç›¸ä¼¼åº¦åº”è¯¥é«˜äºè´Ÿæ ·æœ¬ï¼‰
            correct = pos_sim > neg_sim
            similarity_gap = pos_sim - neg_sim
            
            return {
                "pos_sim": pos_sim,
                "neg_sim": neg_sim, 
                "similarity_gap": similarity_gap,
                "correct": correct,
                "confidence": abs(similarity_gap)
            }
            
        except Exception as e:
            logger.error(f"æ ·æœ¬æµ‹è¯•å¤±è´¥: {e}")
            return None
    
    def run_comparison_demo(self):
        """è¿è¡Œå¯¹æ¯”æ¼”ç¤º"""
        logger.info("ğŸ¯ å¼€å§‹Aè‚¡RAGæ¨¡å‹æ•ˆæœæ¼”ç¤º")
        logger.info("="*80)
        
        if not self.load_models():
            logger.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œæ¼”ç¤º")
            return
        
        print(f"\n{'='*80}")
        print("ğŸ¯ Aè‚¡ç‰¹åŒ–å¯¹æ¯”å­¦ä¹ RAGæ¨¡å‹æ•ˆæœæ¼”ç¤º")
        print(f"{'='*80}")
        print(f"ğŸ“… æ¼”ç¤ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ”¢ æµ‹è¯•æ ·æœ¬æ•°: {len(self.test_samples)}")
        print(f"ğŸ“Š å¯¹æ¯”æ¨¡å‹: è®­ç»ƒæ¨¡å‹ vs åŸºçº¿æ¨¡å‹(BGE-Large-ZH-v1.5)")
        print(f"{'='*80}\n")
        
        total_results = {
            "è®­ç»ƒæ¨¡å‹": {"correct": 0, "total": 0, "avg_gap": 0, "gaps": []},
            "åŸºçº¿æ¨¡å‹": {"correct": 0, "total": 0, "avg_gap": 0, "gaps": []}
        }
        
        for i, sample in enumerate(self.test_samples, 1):
            print(f"ğŸ“‹ æµ‹è¯•æ ·æœ¬ {i}: {sample['category']}")
            print(f"   é”šç‚¹(å‚è€ƒ): {sample['anchor']}")
            print(f"   æ­£æ ·æœ¬(ç›¸ä¼¼): {sample['positive']}")
            print(f"   éš¾è´Ÿæ ·æœ¬(ç›¸å): {sample['hard_negative']}")
            print(f"   è§£é‡Š: {sample['explanation']}")
            print()
            
            # æµ‹è¯•è®­ç»ƒæ¨¡å‹
            trained_result = self.test_single_sample(sample, self.model, "è®­ç»ƒæ¨¡å‹")
            baseline_result = self.test_single_sample(sample, self.baseline_model, "åŸºçº¿æ¨¡å‹")
            
            if trained_result and baseline_result:
                # æ›´æ–°ç»Ÿè®¡
                for model_name, result in [("è®­ç»ƒæ¨¡å‹", trained_result), ("åŸºçº¿æ¨¡å‹", baseline_result)]:
                    total_results[model_name]["total"] += 1
                    if result["correct"]:
                        total_results[model_name]["correct"] += 1
                    total_results[model_name]["gaps"].append(result["similarity_gap"])
                
                print("   ğŸ“Š ç›¸ä¼¼åº¦åˆ†æ:")
                print(f"      æ¨¡å‹ç±»å‹     æ­£æ ·æœ¬ç›¸ä¼¼åº¦  è´Ÿæ ·æœ¬ç›¸ä¼¼åº¦  ç›¸ä¼¼åº¦å·®è·   åˆ¤æ–­ç»“æœ")
                print(f"      {'â”€'*60}")
                
                # è®­ç»ƒæ¨¡å‹ç»“æœ
                trained_status = "âœ… æ­£ç¡®" if trained_result["correct"] else "âŒ é”™è¯¯"
                print(f"      è®­ç»ƒæ¨¡å‹     {trained_result['pos_sim']:.4f}       {trained_result['neg_sim']:.4f}       {trained_result['similarity_gap']:.4f}     {trained_status}")
                
                # åŸºçº¿æ¨¡å‹ç»“æœ  
                baseline_status = "âœ… æ­£ç¡®" if baseline_result["correct"] else "âŒ é”™è¯¯"
                print(f"      åŸºçº¿æ¨¡å‹     {baseline_result['pos_sim']:.4f}       {baseline_result['neg_sim']:.4f}       {baseline_result['similarity_gap']:.4f}     {baseline_status}")
                
                # æ”¹è¿›åˆ†æ
                if trained_result["similarity_gap"] > baseline_result["similarity_gap"]:
                    improvement = (trained_result["similarity_gap"] - baseline_result["similarity_gap"])
                    print(f"      ğŸš€ è®­ç»ƒæ¨¡å‹ç›¸ä¼¼åº¦å·®è·æå‡: +{improvement:.4f}")
                elif trained_result["similarity_gap"] < baseline_result["similarity_gap"]:
                    decrease = (baseline_result["similarity_gap"] - trained_result["similarity_gap"])
                    print(f"      ğŸ“‰ è®­ç»ƒæ¨¡å‹ç›¸ä¼¼åº¦å·®è·ä¸‹é™: -{decrease:.4f}")
                else:
                    print(f"      â¡ï¸  ç›¸ä¼¼åº¦å·®è·ç›¸åŒ")
                
                print()
            else:
                print("   âŒ æµ‹è¯•å¤±è´¥")
                print()
            
            if i < len(self.test_samples):
                print("â”€" * 80 + "\n")
        
        # æ€»ç»“æŠ¥å‘Š
        self.print_summary_report(total_results)
    
    def print_summary_report(self, results: Dict):
        """æ‰“å°æ€»ç»“æŠ¥å‘Š"""
        print(f"\n{'='*80}")
        print("ğŸ“Š æ¼”ç¤ºæ€»ç»“æŠ¥å‘Š")
        print(f"{'='*80}")
        
        for model_name, stats in results.items():
            if stats["total"] > 0:
                accuracy = stats["correct"] / stats["total"]
                avg_gap = np.mean(stats["gaps"])
                
                print(f"\nğŸ¤– {model_name}:")
                print(f"   å‡†ç¡®ç‡: {accuracy:.1%} ({stats['correct']}/{stats['total']})")
                print(f"   å¹³å‡ç›¸ä¼¼åº¦å·®è·: {avg_gap:.4f}")
                print(f"   ç›¸ä¼¼åº¦å·®è·æ ‡å‡†å·®: {np.std(stats['gaps']):.4f}")
        
        # å¯¹æ¯”åˆ†æ
        if results["è®­ç»ƒæ¨¡å‹"]["total"] > 0 and results["åŸºçº¿æ¨¡å‹"]["total"] > 0:
            trained_acc = results["è®­ç»ƒæ¨¡å‹"]["correct"] / results["è®­ç»ƒæ¨¡å‹"]["total"]
            baseline_acc = results["åŸºçº¿æ¨¡å‹"]["correct"] / results["åŸºçº¿æ¨¡å‹"]["total"]
            
            trained_gap = np.mean(results["è®­ç»ƒæ¨¡å‹"]["gaps"])
            baseline_gap = np.mean(results["åŸºçº¿æ¨¡å‹"]["gaps"])
            
            acc_improvement = (trained_acc - baseline_acc) / baseline_acc * 100 if baseline_acc > 0 else 0
            gap_improvement = trained_gap - baseline_gap
            
            print(f"\nğŸ¯ æ€§èƒ½å¯¹æ¯”:")
            print(f"   å‡†ç¡®ç‡æå‡: {acc_improvement:+.1f}%")
            print(f"   ç›¸ä¼¼åº¦å·®è·æ”¹å–„: {gap_improvement:+.4f}")
            
            if acc_improvement > 0 and gap_improvement > 0:
                print(f"   ğŸ‰ è®­ç»ƒæ¨¡å‹è¡¨ç°ä¼˜äºåŸºçº¿æ¨¡å‹!")
            elif acc_improvement > 0 or gap_improvement > 0:
                print(f"   â­ è®­ç»ƒæ¨¡å‹åœ¨æŸäº›æ–¹é¢è¡¨ç°æ›´å¥½")
            else:
                print(f"   ğŸ¤” è®­ç»ƒæ¨¡å‹éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        print(f"\nğŸ’¡ åº”ç”¨å»ºè®®:")
        if results["è®­ç»ƒæ¨¡å‹"]["correct"] / results["è®­ç»ƒæ¨¡å‹"]["total"] > 0.8:
            print("   âœ… æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œå¯ç”¨äºç”Ÿäº§ç¯å¢ƒ")
            print("   âœ… èƒ½å¤Ÿå‡†ç¡®åŒºåˆ†Aè‚¡åˆ©å¥½åˆ©ç©ºä¿¡æ¯")
            print("   âœ… é€‚åˆé›†æˆåˆ°RAGç³»ç»Ÿä¸­ä½¿ç”¨")
        else:
            print("   âš ï¸  å»ºè®®å¢åŠ è®­ç»ƒè½®æ•°æˆ–è°ƒæ•´å‚æ•°")
            print("   âš ï¸  å¯ä»¥è€ƒè™‘å¢åŠ æ›´å¤šè®­ç»ƒæ ·æœ¬")
            print("   âš ï¸  æ£€æŸ¥æ ·æœ¬è´¨é‡å’Œæ ‡æ³¨å‡†ç¡®æ€§")
        
        print(f"\nğŸ”§ ä½¿ç”¨æ–¹å¼:")
        print("   # åœ¨RAGç³»ç»Ÿä¸­å¯ç”¨å¢å¼ºæ¨¡å¼")
        print("   curl -X POST http://localhost:8000/v1/analyse/enhanced_rag_query \\")
        print("     -H 'Content-Type: application/json' \\")
        print("     -d '{\"query\": \"æµ¦å‘é“¶è¡Œä¸šç»©é¢„è­¦æ˜¯åˆ©å¥½è¿˜æ˜¯åˆ©ç©ºï¼Ÿ\", \"detect_conflicts\": true}'")
        
        print(f"\n{'='*80}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è®­ç»ƒæ¨¡å‹æ•ˆæœæ¼”ç¤º")
    parser.add_argument("--model", type=str, help="æŒ‡å®šæ¨¡å‹æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--no-baseline", action="store_true", help="ä¸åŠ è½½åŸºçº¿æ¨¡å‹å¯¹æ¯”")
    
    args = parser.parse_args()
    
    demo = TrainedModelDemo(args.model)
    demo.run_comparison_demo()

if __name__ == "__main__":
    main()
