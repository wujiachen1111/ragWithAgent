#!/usr/bin/env python3
"""
è®­ç»ƒç³»ç»Ÿå®Œæ•´æ€§éªŒè¯è„šæœ¬
éªŒè¯æ‰€æœ‰è®­ç»ƒç›¸å…³ç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import subprocess
from pathlib import Path
import importlib.util
import logging
from typing import Dict, List, Tuple
import json

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TrainingSystemValidator:
    """è®­ç»ƒç³»ç»ŸéªŒè¯å™¨"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent.parent
        self.results = {
            "environment": {},
            "files": {},
            "imports": {},
            "data": {},
            "overall": False
        }
        
    def validate_environment(self) -> Dict[str, bool]:
        """éªŒè¯Pythonç¯å¢ƒ"""
        logger.info("ğŸ” éªŒè¯Pythonç¯å¢ƒ...")
        
        env_results = {}
        
        # æ£€æŸ¥Pythonç‰ˆæœ¬
        python_version = sys.version_info
        env_results["python_version"] = f"{python_version.major}.{python_version.minor}.{python_version.micro}"
        env_results["python_valid"] = python_version >= (3, 8)
        
        if env_results["python_valid"]:
            logger.info(f"âœ… Pythonç‰ˆæœ¬: {env_results['python_version']}")
        else:
            logger.error(f"âŒ Pythonç‰ˆæœ¬è¿‡ä½: {env_results['python_version']}, éœ€è¦ >= 3.8")
        
        # æ£€æŸ¥åŸºç¡€åŒ…
        required_packages = {
            "torch": "PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶",
            "sentence_transformers": "å¥å­è½¬æ¢å™¨",
            "sklearn": "æœºå™¨å­¦ä¹ åº“",
            "numpy": "æ•°å€¼è®¡ç®—åº“",
            "matplotlib": "ç»˜å›¾åº“",
            "pandas": "æ•°æ®å¤„ç†åº“"
        }
        
        for package, desc in required_packages.items():
            try:
                __import__(package.replace("-", "_"))
                env_results[f"package_{package}"] = True
                logger.info(f"âœ… {desc}: {package}")
            except ImportError:
                env_results[f"package_{package}"] = False
                logger.warning(f"âš ï¸  ç¼ºå°‘ä¾èµ–: {package} ({desc})")
        
        return env_results
    
    def validate_files(self) -> Dict[str, bool]:
        """éªŒè¯æ–‡ä»¶å®Œæ•´æ€§"""
        logger.info("ğŸ“ éªŒè¯æ–‡ä»¶å®Œæ•´æ€§...")
        
        file_results = {}
        
        # å…³é”®æ–‡ä»¶åˆ—è¡¨
        critical_files = {
            "è®­ç»ƒè„šæœ¬": "tools/development/training/train_contrastive_rag.py",
            "è¯„ä¼°è„šæœ¬": "tools/development/testing/evaluate_rag_performance.py", 
            "å¿«é€Ÿè®­ç»ƒè„šæœ¬": "tools/development/quick_train_test.py",
            "ç¯å¢ƒé…ç½®è„šæœ¬": "tools/development/setup/setup_training_environment.py",
            "æ ·æœ¬æ•°æ®": "services/decision_engine/contrastive_learning_samples.py",
            "RAGå¢å¼ºå™¨": "services/decision_engine/contrastive_rag_enhancer.py",
            "ä¸»æœåŠ¡": "services/decision_engine/main.py"
        }
        
        for name, filepath in critical_files.items():
            full_path = self.project_root / filepath
            exists = full_path.exists()
            file_results[name] = exists
            
            if exists:
                logger.info(f"âœ… {name}: {filepath}")
            else:
                logger.error(f"âŒ {name}: {filepath} - æ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ£€æŸ¥é…ç½®ç›®å½•
        config_dirs = [
            "configs/training",
            "checkpoints", 
            "logs/tensorboard",
            "results"
        ]
        
        for dir_path in config_dirs:
            full_path = self.project_root / dir_path
            exists = full_path.exists() or self._can_create_dir(full_path)
            file_results[f"dir_{dir_path.replace('/', '_')}"] = exists
            
            if exists:
                logger.info(f"âœ… ç›®å½•: {dir_path}")
            else:
                logger.warning(f"âš ï¸  ç›®å½•ä¸å­˜åœ¨: {dir_path} (å°†è‡ªåŠ¨åˆ›å»º)")
        
        return file_results
    
    def _can_create_dir(self, path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ›å»ºç›®å½•"""
        try:
            path.mkdir(parents=True, exist_ok=True)
            return True
        except PermissionError:
            return False
    
    def validate_imports(self) -> Dict[str, bool]:
        """éªŒè¯å…³é”®æ¨¡å—å¯¼å…¥"""
        logger.info("ğŸ“¦ éªŒè¯æ¨¡å—å¯¼å…¥...")
        
        import_results = {}
        
        # æ·»åŠ é¡¹ç›®è·¯å¾„
        sys.path.append(str(self.project_root / "services" / "decision_engine"))
        
        # å…³é”®æ¨¡å—
        modules = {
            "å¯¹æ¯”å­¦ä¹ æ ·æœ¬": ("contrastive_learning_samples", ["A_STOCK_CONTRASTIVE_SAMPLES", "SentimentLabel"]),
            "RAGå¢å¼ºå™¨": ("contrastive_rag_enhancer", ["ContrastiveEmbeddingModel", "ContrastiveTrainingConfig"])
        }
        
        for name, (module_name, attributes) in modules.items():
            try:
                module = importlib.import_module(module_name)
                import_results[f"module_{module_name}"] = True
                logger.info(f"âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ: {name}")
                
                # æ£€æŸ¥å±æ€§
                for attr in attributes:
                    if hasattr(module, attr):
                        import_results[f"attr_{module_name}_{attr}"] = True
                        logger.info(f"  âœ… å±æ€§: {attr}")
                    else:
                        import_results[f"attr_{module_name}_{attr}"] = False
                        logger.warning(f"  âš ï¸  ç¼ºå°‘å±æ€§: {attr}")
                        
            except ImportError as e:
                import_results[f"module_{module_name}"] = False
                logger.error(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {name} - {e}")
        
        return import_results
    
    def validate_data(self) -> Dict[str, bool]:
        """éªŒè¯è®­ç»ƒæ•°æ®"""
        logger.info("ğŸ“Š éªŒè¯è®­ç»ƒæ•°æ®...")
        
        data_results = {}
        
        try:
            sys.path.append(str(self.project_root / "services" / "decision_engine"))
            from contrastive_learning_samples import A_STOCK_CONTRASTIVE_SAMPLES
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            total_samples = 0
            categories = list(A_STOCK_CONTRASTIVE_SAMPLES.keys())
            
            data_results["categories_count"] = len(categories)
            data_results["has_categories"] = len(categories) > 0
            
            for category, samples in A_STOCK_CONTRASTIVE_SAMPLES.items():
                category_count = len(samples)
                total_samples += category_count
                data_results[f"category_{category}"] = category_count > 0
                
                logger.info(f"âœ… ç±»åˆ«: {category} - {category_count}ä¸ªæ ·æœ¬")
                
                # æ£€æŸ¥æ ·æœ¬ç»“æ„
                if samples:
                    sample = samples[0]
                    required_keys = ['anchor', 'hard_negative', 'anchor_label', 'explanation']
                    for key in required_keys:
                        if key in sample:
                            data_results[f"sample_key_{key}"] = True
                        else:
                            data_results[f"sample_key_{key}"] = False
                            logger.warning(f"âš ï¸  æ ·æœ¬ç¼ºå°‘å­—æ®µ: {key}")
            
            data_results["total_samples"] = total_samples
            data_results["sufficient_data"] = total_samples >= 20  # æœ€å°‘20ä¸ªæ ·æœ¬
            
            logger.info(f"âœ… æ€»æ ·æœ¬æ•°: {total_samples}")
            logger.info(f"âœ… ç±»åˆ«æ•°: {len(categories)}")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
            data_results["data_accessible"] = False
            
        return data_results
    
    def validate_scripts_syntax(self) -> Dict[str, bool]:
        """éªŒè¯è„šæœ¬è¯­æ³•"""
        logger.info("ğŸ” éªŒè¯è„šæœ¬è¯­æ³•...")
        
        syntax_results = {}
        
        script_files = [
            "tools/development/training/train_contrastive_rag.py",
            "tools/development/testing/evaluate_rag_performance.py",
            "tools/development/quick_train_test.py",
            "tools/development/setup/setup_training_environment.py"
        ]
        
        for script_path in script_files:
            full_path = self.project_root / script_path
            script_name = Path(script_path).name
            
            if not full_path.exists():
                syntax_results[script_name] = False
                logger.error(f"âŒ è„šæœ¬ä¸å­˜åœ¨: {script_path}")
                continue
            
            try:
                # è¯­æ³•æ£€æŸ¥
                with open(full_path, 'r', encoding='utf-8') as f:
                    source = f.read()
                compile(source, str(full_path), 'exec')
                
                syntax_results[script_name] = True
                logger.info(f"âœ… è¯­æ³•æ£€æŸ¥é€šè¿‡: {script_name}")
                
            except SyntaxError as e:
                syntax_results[script_name] = False
                logger.error(f"âŒ è¯­æ³•é”™è¯¯: {script_name} - ç¬¬{e.lineno}è¡Œ: {e.msg}")
            except Exception as e:
                syntax_results[script_name] = False
                logger.error(f"âŒ æ£€æŸ¥å¤±è´¥: {script_name} - {e}")
        
        return syntax_results
    
    def run_quick_validation(self) -> bool:
        """è¿è¡Œå¿«é€ŸéªŒè¯"""
        logger.info("âš¡ æ‰§è¡Œå¿«é€ŸéªŒè¯æµ‹è¯•...")
        
        try:
            # æµ‹è¯•å¿«é€Ÿè®­ç»ƒè„šæœ¬çš„å¸®åŠ©åŠŸèƒ½
            quick_script = self.project_root / "tools/development/quick_train_test.py"
            result = subprocess.run(
                [sys.executable, str(quick_script), "--usage"],
                capture_output=True,
                text=True,
                cwd=self.project_root,
                timeout=30
            )
            
            if result.returncode == 0:
                logger.info("âœ… å¿«é€Ÿè®­ç»ƒè„šæœ¬è¿è¡Œæ­£å¸¸")
                return True
            else:
                logger.warning(f"âš ï¸  å¿«é€Ÿè®­ç»ƒè„šæœ¬è­¦å‘Š: {result.stderr}")
                return True  # å¸®åŠ©ä¿¡æ¯å¯èƒ½å¯¼è‡´é0é€€å‡ºç 
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ è„šæœ¬è¿è¡Œè¶…æ—¶")
            return False
        except Exception as e:
            logger.error(f"âŒ è„šæœ¬è¿è¡Œå¤±è´¥: {e}")
            return False
    
    def generate_report(self) -> Dict:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        logger.info("ğŸ“‹ ç”ŸæˆéªŒè¯æŠ¥å‘Š...")
        
        # æ‰§è¡Œæ‰€æœ‰éªŒè¯
        self.results["environment"] = self.validate_environment()
        self.results["files"] = self.validate_files()
        self.results["imports"] = self.validate_imports() 
        self.results["data"] = self.validate_data()
        self.results["syntax"] = self.validate_scripts_syntax()
        self.results["quick_test"] = self.run_quick_validation()
        
        # è®¡ç®—æ€»ä½“ç»“æœ
        critical_checks = [
            self.results["environment"].get("python_valid", False),
            self.results["files"].get("è®­ç»ƒè„šæœ¬", False),
            self.results["files"].get("å¿«é€Ÿè®­ç»ƒè„šæœ¬", False),
            self.results["imports"].get("module_contrastive_learning_samples", False),
            self.results["data"].get("has_categories", False),
            self.results["data"].get("sufficient_data", False)
        ]
        
        self.results["overall"] = all(critical_checks)
        
        return self.results
    
    def print_summary(self):
        """æ‰“å°éªŒè¯æ€»ç»“"""
        logger.info("="*60)
        logger.info("ğŸ¯ è®­ç»ƒç³»ç»ŸéªŒè¯æ€»ç»“")
        logger.info("="*60)
        
        if self.results["overall"]:
            logger.info("ğŸ‰ éªŒè¯é€šè¿‡ï¼è®­ç»ƒç³»ç»Ÿå·²å‡†å¤‡å°±ç»ª")
            logger.info("")
            logger.info("âœ… å¯ä»¥å¼€å§‹è®­ç»ƒ:")
            logger.info("   python tools/development/quick_train_test.py --full-pipeline")
            logger.info("")
            logger.info("ğŸ“Š é¢„æœŸæ•ˆæœ:")
            logger.info("   - è®­ç»ƒæ—¶é—´: GPUçº¦20-30åˆ†é’Ÿï¼ŒCPUçº¦2-3å°æ—¶")
            logger.info("   - å‡†ç¡®ç‡: > 90%")
            logger.info("   - æ€§èƒ½æå‡: 15-25%")
        else:
            logger.error("âŒ éªŒè¯å¤±è´¥ï¼å­˜åœ¨ä»¥ä¸‹é—®é¢˜:")
            
            # è¯¦ç»†é—®é¢˜åˆ†æ
            if not self.results["environment"].get("python_valid", False):
                logger.error("   - Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦ >= 3.8")
            
            missing_packages = [k for k, v in self.results["environment"].items() 
                              if k.startswith("package_") and not v]
            if missing_packages:
                logger.error(f"   - ç¼ºå°‘PythonåŒ…: {[k.replace('package_', '') for k in missing_packages]}")
                logger.error("     å®‰è£…å‘½ä»¤: pip install torch sentence-transformers scikit-learn matplotlib")
            
            missing_files = [k for k, v in self.results["files"].items() if not v]
            if missing_files:
                logger.error(f"   - ç¼ºå°‘å…³é”®æ–‡ä»¶: {missing_files}")
            
            if not self.results["data"].get("sufficient_data", False):
                logger.error("   - è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè¯·æ£€æŸ¥æ ·æœ¬æ•°æ®")
        
        logger.info("="*60)

def main():
    """ä¸»å‡½æ•°"""
    validator = TrainingSystemValidator()
    
    print("ğŸ” æ™ºç­–(InsightFolio) è®­ç»ƒç³»ç»ŸéªŒè¯å·¥å…·")
    print("="*60)
    
    # è¿è¡ŒéªŒè¯
    results = validator.generate_report()
    
    # æ‰“å°æ€»ç»“
    validator.print_summary()
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = validator.project_root / "validation_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    # é€€å‡ºç 
    sys.exit(0 if results["overall"] else 1)

if __name__ == "__main__":
    main()
