"""
æ–°é—»èˆ†æƒ…åˆ†æç³»ç»Ÿ - Streamlitå‰ç«¯ç•Œé¢
"""
import streamlit as st
import requests
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import json
import time

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ–°é—»èˆ†æƒ…åˆ†æç³»ç»Ÿ",
    page_icon="ï¿½",
    layout="wide",
    initial_sidebar_state="expanded"
)

# APIåŸºç¡€URL
API_BASE_URL = "http://localhost:8000/api"

@st.cache_data(ttl=60)  # ç¼“å­˜1åˆ†é’Ÿ
def fetch_api_data(endpoint: str, params: dict = None):
    """ä»APIè·å–æ•°æ®"""
    try:
        response = requests.get(f"{API_BASE_URL}{endpoint}", params=params)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"APIè¯·æ±‚å¤±è´¥: {e}")
        return None

@st.cache_data(ttl=30)
def check_api_status():
    """æ£€æŸ¥APIè¿æ¥çŠ¶æ€"""
    try:
        response = requests.get("http://localhost:8000/health", timeout=5)
        return response.json()
    except:
        return {"status": "disconnected"}

def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ“° æ–°é—»èˆ†æƒ…åˆ†æç³»ç»Ÿ")
    
    # è‡ªåŠ¨åˆ·æ–°è®¾ç½®
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        auto_refresh = st.checkbox("ğŸ”„ è‡ªåŠ¨åˆ·æ–°", value=True)
    with col2:
        refresh_interval = st.selectbox(
            "åˆ·æ–°é—´éš”", 
            options=[30, 60, 300, 600],
            index=2,
            format_func=lambda x: f"{x}ç§’"
        )
    with col3:
        if auto_refresh:
            st.write(f"â° æ•°æ®å°†æ¯{refresh_interval}ç§’è‡ªåŠ¨æ›´æ–°")
            # ä½¿ç”¨JavaScriptè¿›è¡Œé¡µé¢è‡ªåŠ¨åˆ·æ–°
            st.markdown(f"""
                <script>
                setTimeout(function(){{
                    window.location.reload();
                }}, {refresh_interval * 1000});
                </script>
            """, unsafe_allow_html=True)
        else:
            st.write("ğŸ›‘ è‡ªåŠ¨åˆ·æ–°å·²å…³é—­")
    
    st.markdown("---")
    
    # æ£€æŸ¥APIçŠ¶æ€
    api_status = check_api_status()
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ æ§åˆ¶é¢æ¿")
        
        # APIçŠ¶æ€æ˜¾ç¤º
        if api_status.get("status") == "healthy":
            st.success("âœ… APIæœåŠ¡æ­£å¸¸")
            st.success("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸") 
            st.success("âœ… Redisç¼“å­˜æ­£å¸¸")
            if api_status.get("chroma") == "connected":
                st.success("âœ… Chromaå‘é‡åº“æ­£å¸¸")
            else:
                st.warning("âš ï¸ Chromaå‘é‡åº“ç¦»çº¿")
        else:
            st.error("âŒ APIæœåŠ¡ç¦»çº¿")
            st.info("è¯·ç¡®ä¿åç«¯æœåŠ¡å·²å¯åŠ¨")
        
        st.markdown("---")
        
        # æ—¶é—´èŒƒå›´é€‰æ‹©
        time_range = st.selectbox(
            "ğŸ“… æ—¶é—´èŒƒå›´",
            options=[1, 6, 12, 24, 48, 72],
            index=3,
            format_func=lambda x: f"æœ€è¿‘ {x} å°æ—¶"
        )
        
        # æ•°æ®æºè¿‡æ»¤
        source_filter = st.selectbox(
            "ğŸ“¡ æ•°æ®æº",
            options=["å…¨éƒ¨", "google_news", "gdelt", "twitter", "chinese_finance"]
        )
        source_param = None if source_filter == "å…¨éƒ¨" else source_filter
        
        # æƒ…æ„Ÿè¿‡æ»¤
        sentiment_filter = st.selectbox(
            "ğŸ˜Š æƒ…æ„Ÿè¿‡æ»¤",
            options=["å…¨éƒ¨", "positive", "negative", "neutral"]
        )
        sentiment_param = None if sentiment_filter == "å…¨éƒ¨" else sentiment_filter
        
        # åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ åˆ·æ–°æ•°æ®"):
            st.cache_data.clear()
            st.rerun()
    
    # ä¸»é¡µé¢å¸ƒå±€
    if api_status.get("status") == "healthy":
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š æ¦‚è§ˆ", "ğŸ“° æ–°é—»", "ğŸ” åˆ†æ", "ğŸ“ˆ ç»Ÿè®¡"])
        
        with tab1:
            show_overview(time_range)
        
        with tab2:
            show_news_list(time_range, source_param)
        
        with tab3:
            show_analysis_results(time_range, sentiment_param)
        
        with tab4:
            show_statistics(time_range)
    else:
        st.error("âš ï¸ APIæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡")
        st.info("è¿è¡Œå‘½ä»¤: `python -m app.main` å¯åŠ¨APIæœåŠ¡")

def show_overview(time_range: int):
    """æ˜¾ç¤ºç³»ç»Ÿæ¦‚è§ˆ"""
    st.header("ğŸ¯ ç³»ç»Ÿæ¦‚è§ˆ")
    
    # è·å–ç»Ÿè®¡æ•°æ®
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ï¿½ æ•°æ®æºçŠ¶æ€")
        source_stats = fetch_api_data("/news/sources/stats", {"hours": time_range})
        
        if source_stats:
            total_news = source_stats.get("total_news", 0)
            active_sources = source_stats.get("summary", {}).get("active_sources", 0)
            
            # æ˜¾ç¤ºæ€»ä½“æŒ‡æ ‡
            col_a, col_b = st.columns(2)
            with col_a:
                st.metric("ğŸ“° æ€»æ–°é—»æ•°", total_news)
            with col_b:
                st.metric("ï¿½ æ´»è·ƒæ•°æ®æº", active_sources)
            
            # æ•°æ®æºè¯¦æƒ…
            if "sources" in source_stats:
                source_data = []
                for source, stats in source_stats["sources"].items():
                    source_data.append({
                        "æ•°æ®æº": source,
                        "æ–°é—»æ•°é‡": stats["count"],
                        "æœ€æ–°æ›´æ–°": stats["latest"]
                    })
                
                if source_data:
                    df_sources = pd.DataFrame(source_data)
                    st.dataframe(df_sources, use_container_width=True)
        else:
            st.info("æš‚æ— æ•°æ®æºç»Ÿè®¡")
    
    with col2:
        st.subheader("ğŸ” æƒ…æ„Ÿåˆ†ææ¦‚å†µ")
        sentiment_stats = fetch_api_data("/analysis/stats/sentiment", {"hours": time_range})
        
        if sentiment_stats:
            total_analyses = sentiment_stats.get("total_analyses", 0)
            avg_confidence = sentiment_stats.get("confidence_stats", {}).get("average", 0)
            
            # æ˜¾ç¤ºåˆ†ææŒ‡æ ‡
            col_c, col_d = st.columns(2)
            with col_c:
                st.metric("ğŸ” åˆ†ææ€»æ•°", total_analyses)
            with col_d:
                st.metric("ğŸ¯ å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.2f}")
            
            # æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
            sentiment_dist = sentiment_stats.get("sentiment_distribution", {})
            if any(sentiment_dist.values()):
                fig_pie = px.pie(
                    values=list(sentiment_dist.values()),
                    names=list(sentiment_dist.keys()),
                    title="æƒ…æ„Ÿåˆ†å¸ƒ",
                    color_discrete_map={
                        'positive': '#00C851',
                        'negative': '#FF4444',
                        'neutral': '#FFBB33'
                    }
                )
                st.plotly_chart(fig_pie, use_container_width=True)
        else:
            st.info("æš‚æ— åˆ†æç»Ÿè®¡")

def show_news_list(time_range: int, source_filter: str):
    """æ˜¾ç¤ºæ–°é—»åˆ—è¡¨"""
    st.header("ğŸ“° æ–°é—»åˆ—è¡¨")
    
    # æœç´¢æ¡†
    keyword = st.text_input("ğŸ” å…³é”®è¯æœç´¢", placeholder="è¾“å…¥å…³é”®è¯æœç´¢æ–°é—»...")
    
    # è·å–æ–°é—»æ•°æ®
    params = {
        "hours": time_range,
        "limit": 50
    }
    if source_filter:
        params["source"] = source_filter
    if keyword:
        params["keyword"] = keyword
    
    news_data = fetch_api_data("/news/", params)
    
    if news_data and news_data.get("data"):
        news_list = news_data["data"]
        
        # æ˜¾ç¤ºåˆ†é¡µä¿¡æ¯
        pagination = news_data.get("pagination", {})
        st.info(f"å…±æ‰¾åˆ° {pagination.get('total', 0)} æ¡æ–°é—»ï¼Œæ˜¾ç¤ºå‰ {len(news_list)} æ¡")
        
        # æ˜¾ç¤ºæ–°é—»å¡ç‰‡
        for news in news_list:
            with st.container():
                col1, col2 = st.columns([4, 1])
                
                with col1:
                    st.markdown(f"### {news['title']}")
                    st.markdown(f"**æ¥æº**: {news['source']} | **å‘å¸ƒæ—¶é—´**: {news['published_at']}")
                    
                    if news['content'] and len(news['content']) > 100:
                        st.markdown(f"{news['content'][:100]}...")
                        with st.expander("æŸ¥çœ‹å®Œæ•´å†…å®¹"):
                            st.markdown(news['content'])
                    elif news['content']:
                        st.markdown(news['content'])
                
                with col2:
                    if st.button("ğŸ” è¯¦æƒ…", key=f"detail_{news['id']}"):
                        show_news_detail(news['id'])
                
                st.markdown("---")
    else:
        st.info("æš‚æ— æ–°é—»æ•°æ®")

def show_news_detail(news_id: str):
    """æ˜¾ç¤ºæ–°é—»è¯¦æƒ…"""
    detail_data = fetch_api_data(f"/news/{news_id}")
    
    if detail_data:
        news = detail_data["news"]
        analysis = detail_data.get("analysis")
        
        with st.expander(f"æ–°é—»è¯¦æƒ…: {news['title']}", expanded=True):
            st.markdown(f"**æ¥æº**: {news['source']} | **å‘å¸ƒæ—¶é—´**: {news['published_at']}")
            
            if news['content']:
                st.markdown("### å†…å®¹")
                st.markdown(news['content'])
            
            if analysis:
                st.markdown("### åˆ†æç»“æœ")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    sentiment_color = {
                        'positive': 'ğŸŸ¢',
                        'negative': 'ğŸ”´',
                        'neutral': 'ğŸŸ¡'
                    }.get(analysis['sentiment_label'], 'âšª')
                    st.metric(
                        "æƒ…æ„Ÿå€¾å‘",
                        f"{sentiment_color} {analysis['sentiment_label']}"
                    )
                
                with col2:
                    st.metric("ç½®ä¿¡åº¦", f"{analysis['confidence_score']:.2f}")
                
                with col3:
                    st.metric("å¸‚åœºå½±å“", analysis.get('market_impact_level', 'N/A'))
                
                # æ˜¾ç¤ºè¯¦ç»†åˆ†æç»“æœ
                if analysis.get('analysis_result'):
                    result = analysis['analysis_result']
                    if isinstance(result, str):
                        try:
                            result = json.loads(result)
                        except:
                            pass
                    
                    if isinstance(result, dict):
                        if 'keywords' in result:
                            st.markdown("**å…³é”®è¯**: " + ", ".join(result['keywords']))
                        if 'summary' in result:
                            st.markdown("**æ‘˜è¦**: " + result['summary'])
                        if 'reasoning' in result:
                            st.markdown("**åˆ†ææ¨ç†**: " + result['reasoning'])

def show_analysis_results(time_range: int, sentiment_filter: str):
    """æ˜¾ç¤ºåˆ†æç»“æœ"""
    st.header("ï¿½ åˆ†æç»“æœ")
    
    # è·å–åˆ†ææ•°æ®
    params = {
        "hours": time_range,
        "limit": 50
    }
    if sentiment_filter:
        params["sentiment"] = sentiment_filter
    
    analysis_data = fetch_api_data("/analysis/", params)
    
    if analysis_data and analysis_data.get("data"):
        analyses = analysis_data["data"]
        
        # æ˜¾ç¤ºåˆ†é¡µä¿¡æ¯
        pagination = analysis_data.get("pagination", {})
        st.info(f"å…±æ‰¾åˆ° {pagination.get('total', 0)} æ¡åˆ†æç»“æœï¼Œæ˜¾ç¤ºå‰ {len(analyses)} æ¡")
        
        # åˆ›å»ºDataFrameæ˜¾ç¤º
        analysis_list = []
        for item in analyses:
            analysis = item["analysis"]
            news = item["news"]
            
            analysis_list.append({
                "æ–°é—»æ ‡é¢˜": news["title"][:50] + "..." if len(news["title"]) > 50 else news["title"],
                "æƒ…æ„Ÿ": analysis["sentiment_label"],
                "ç½®ä¿¡åº¦": f"{analysis['confidence_score']:.2f}",
                "å¸‚åœºå½±å“": analysis.get("market_impact_level", "N/A"),
                "æ¥æº": news["source"],
                "åˆ†ææ—¶é—´": analysis["analysis_timestamp"]
            })
        
        if analysis_list:
            df_analysis = pd.DataFrame(analysis_list)
            st.dataframe(df_analysis, use_container_width=True)
    else:
        st.info("æš‚æ— åˆ†ææ•°æ®")

def show_statistics(time_range: int):
    """æ˜¾ç¤ºç»Ÿè®¡å›¾è¡¨"""
    st.header("ğŸ“ˆ ç»Ÿè®¡åˆ†æ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š æƒ…æ„Ÿè¶‹åŠ¿")
        timeline_data = fetch_api_data("/analysis/stats/timeline", {
            "hours": time_range,
            "interval": max(1, time_range // 12)
        })
        
        if timeline_data and timeline_data.get("timeline"):
            timeline = timeline_data["timeline"]
            
            # å‡†å¤‡æ—¶é—´çº¿æ•°æ®
            timestamps = [item["timestamp"] for item in timeline]
            positive_counts = [item["sentiment_distribution"]["positive"] for item in timeline]
            negative_counts = [item["sentiment_distribution"]["negative"] for item in timeline]
            neutral_counts = [item["sentiment_distribution"]["neutral"] for item in timeline]
            
            # åˆ›å»ºæ—¶é—´çº¿å›¾
            fig_timeline = go.Figure()
            fig_timeline.add_trace(go.Scatter(
                x=timestamps, y=positive_counts,
                mode='lines+markers', name='æ­£é¢', line=dict(color='green')
            ))
            fig_timeline.add_trace(go.Scatter(
                x=timestamps, y=negative_counts,
                mode='lines+markers', name='è´Ÿé¢', line=dict(color='red')
            ))
            fig_timeline.add_trace(go.Scatter(
                x=timestamps, y=neutral_counts,
                mode='lines+markers', name='ä¸­æ€§', line=dict(color='orange')
            ))
            
            fig_timeline.update_layout(
                title="æƒ…æ„Ÿåˆ†ææ—¶é—´è¶‹åŠ¿",
                xaxis_title="æ—¶é—´",
                yaxis_title="æ•°é‡",
                hovermode='x unified'
            )
            
            st.plotly_chart(fig_timeline, use_container_width=True)
        else:
            st.info("æš‚æ— æ—¶é—´çº¿æ•°æ®")
    
    with col2:
        st.subheader("ğŸ”¥ çƒ­é—¨å…³é”®è¯")
        keywords_data = fetch_api_data("/analysis/keywords/trending", {
            "hours": time_range,
            "limit": 15
        })
        
        if keywords_data and keywords_data.get("trending_keywords"):
            keywords = keywords_data["trending_keywords"]
            
            if keywords:
                # åˆ›å»ºå…³é”®è¯æ¡å½¢å›¾
                df_keywords = pd.DataFrame(keywords)
                fig_keywords = px.bar(
                    df_keywords.head(10),
                    x="count",
                    y="keyword",
                    orientation='h',
                    title="çƒ­é—¨å…³é”®è¯ TOP 10",
                    labels={"count": "å‡ºç°æ¬¡æ•°", "keyword": "å…³é”®è¯"}
                )
                fig_keywords.update_layout(yaxis={'categoryorder':'total ascending'})
                
                st.plotly_chart(fig_keywords, use_container_width=True)
                
                # æ˜¾ç¤ºå®Œæ•´å…³é”®è¯åˆ—è¡¨
                with st.expander("æŸ¥çœ‹å®Œæ•´å…³é”®è¯åˆ—è¡¨"):
                    for i, kw in enumerate(keywords, 1):
                        st.markdown(f"{i}. **{kw['keyword']}** ({kw['count']}æ¬¡)")
            else:
                st.info("æš‚æ— å…³é”®è¯æ•°æ®")
        else:
            st.info("æš‚æ— å…³é”®è¯ç»Ÿè®¡")

if __name__ == "__main__":
    main()
